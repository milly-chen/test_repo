---
title: "Modeling Medical Insurance Data"
author: "Melissa Chen"
date: "11/17/2020"
output: html_document
---

<link href="/rmarkdown-libs/anchor-sections/anchor-sections.css" rel="stylesheet" />
<script src="/rmarkdown-libs/anchor-sections/anchor-sections.js"></script>


<div id="introducing-dataset" class="section level3">
<h3>Introducing Dataset</h3>
<pre class="r"><code>library(tidyverse)
insurance &lt;- read.csv(&quot;https://drive.google.com/uc?export=download&amp;id=1wYKOxnrDBJlyefVwvyUIzAmGn_VMpE9M&quot;)
glimpse(insurance)</code></pre>
<pre><code>## Rows: 1,338
## Columns: 7
## $ age      &lt;int&gt; 19, 18, 28, 33, 32, 31, 46, 37, 37, 60, 25, 62, 23, 56, 27...
## $ sex      &lt;chr&gt; &quot;female&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;male&quot;, &quot;female&quot;, &quot;femal...
## $ bmi      &lt;dbl&gt; 27.900, 33.770, 33.000, 22.705, 28.880, 25.740, 33.440, 27...
## $ children &lt;int&gt; 0, 1, 3, 0, 0, 0, 1, 3, 2, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0...
## $ smoker   &lt;chr&gt; &quot;yes&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no&quot;, &quot;no...
## $ region   &lt;chr&gt; &quot;southwest&quot;, &quot;southeast&quot;, &quot;southeast&quot;, &quot;northwest&quot;, &quot;north...
## $ charges  &lt;dbl&gt; 16884.924, 1725.552, 4449.462, 21984.471, 3866.855, 3756.6...</code></pre>
<pre class="r"><code>insurance &lt;- insurance[,c(1,2,3,7,4,5,6)]

# dummy coding
insurance &lt;- insurance %&gt;% mutate(sex=ifelse(insurance$sex==&quot;female&quot;,1,0),smoker =ifelse(insurance$smoker==&quot;yes&quot;, 1, 0))</code></pre>
<p>This dataset includes variables for patient age, sex, BMI, children, smoker, region, and charges. Age, BMI (kg/m^2), and sex are pretty straight forward variables and require no further explaination. However, the smoker variable indicates whether the patient smokes and the region variable indicates which part of the US the patient is from. Children refers to the number of children the patient has and charges in dollars indicates how much a patient was billed by their health insurance. I dummy coded sex and smoking status to where 0 in either group indicates that the patient is a male or that the patient is not a smoker. There are 1338 observations in this dataset.</p>
</div>
<div id="manova-test" class="section level3">
<h3>MANOVA Test</h3>
<pre class="r"><code># running MANOVA
man1 &lt;- manova(cbind(charges, bmi, children, age) ~ region, data = insurance)
summary(man1)</code></pre>
<pre><code>##             Df   Pillai approx F num Df den Df    Pr(&gt;F)    
## region       3 0.088794   10.164     12   3999 &lt; 2.2e-16 ***
## Residuals 1334                                              
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<pre class="r"><code>## multivariate normality
ggplot(insurance, aes(x = charges, y = bmi)) + geom_point(alpha = .5) + geom_density_2d() + facet_wrap(~region) </code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-2-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## variance-covariance homogeneity
covmats &lt;- insurance %&gt;% group_by(region) %&gt;% do(covs=cov(.[3:4]))
for(i in 1:4){print(as.character(covmats$region[i])); print(covmats$covs[[i]])}</code></pre>
<pre><code>## [1] &quot;northeast&quot;
##                 bmi      charges
## bmi        35.25406     15485.67
## charges 15485.67295 126693102.65
## [1] &quot;northwest&quot;
##                 bmi      charges
## bmi        26.38635     10298.63
## charges 10298.63059 122595316.36
## [1] &quot;southeast&quot;
##                 bmi      charges
## bmi        41.95992     12940.97
## charges 12940.97080 195191595.78
## [1] &quot;southwest&quot;
##                 bmi      charges
## bmi        32.39699     14664.56
## charges 14664.55540 133568388.77</code></pre>
<pre class="r"><code>## linear relationship btw DV
ggplot(insurance, aes(charges, bmi)) + geom_point() + geom_smooth(method=lm) </code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-2-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code># running univariate ANOVA
summary.aov(man1)</code></pre>
<pre><code>##  Response charges :
##               Df     Sum Sq   Mean Sq F value  Pr(&gt;F)  
## region         3 1.3008e+09 433586560  2.9696 0.03089 *
## Residuals   1334 1.9477e+11 146007093                  
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response bmi :
##               Df Sum Sq Mean Sq F value    Pr(&gt;F)    
## region         3   4056 1351.96  39.495 &lt; 2.2e-16 ***
## Residuals   1334  45664   34.23                      
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
##  Response children :
##               Df  Sum Sq Mean Sq F value Pr(&gt;F)
## region         3    3.13  1.0433  0.7175 0.5416
## Residuals   1334 1939.82  1.4541               
## 
##  Response age :
##               Df Sum Sq Mean Sq F value Pr(&gt;F)
## region         3     47  15.782  0.0798  0.971
## Residuals   1334 263878 197.810</code></pre>
<pre class="r"><code>insurance %&gt;% group_by(region) %&gt;% summarize(mean(bmi), mean(charges))</code></pre>
<pre><code>## # A tibble: 4 x 3
##   region    `mean(bmi)` `mean(charges)`
##   &lt;chr&gt;           &lt;dbl&gt;           &lt;dbl&gt;
## 1 northeast        29.2          13406.
## 2 northwest        29.2          12418.
## 3 southeast        33.4          14735.
## 4 southwest        30.6          12347.</code></pre>
<pre class="r"><code># running post hoc t test
pairwise.t.test(insurance$bmi, insurance$region, p.adj=&quot;none&quot;) # for BMI</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  insurance$bmi and insurance$region 
## 
##           northeast northwest southeast
## northwest 0.9544    -         -        
## southeast &lt; 2e-16   &lt; 2e-16   -        
## southwest 0.0020    0.0024    8.5e-10  
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>pairwise.t.test(insurance$charges, insurance$region, p.adj=&quot;none&quot;) # for charges</code></pre>
<pre><code>## 
##  Pairwise comparisons using t tests with pooled SD 
## 
## data:  insurance$charges and insurance$region 
## 
##           northeast northwest southeast
## northwest 0.2974    -         -        
## southeast 0.1501    0.0121    -        
## southwest 0.2643    0.9406    0.0097   
## 
## P value adjustment method: none</code></pre>
<pre class="r"><code>#bonferroni
0.05/17</code></pre>
<pre><code>## [1] 0.002941176</code></pre>
<pre class="r"><code>#probability of type I
1-(0.95^17)</code></pre>
<pre><code>## [1] 0.5818797</code></pre>
<p>Since I have computed 17 tests in total (1 MANOVA, 4 ANOVA, 12 t tests), the adjusted significance level is now 0.00294. There is a 0.5818 chance of performing a type I error if the significance level was not adjusted.</p>
<p>Performing a MANOVA test to see whether differences in regionality of patients show a mean difference in the numerical variables charges, BMI, children, and age. The resulting p value is extremely small (p &lt; 2.2e-16) and indicates that there is a mean difference amongst the tested numeric variables based on regionality.</p>
<p>Therefore, an ANOVA test was computed and there was only significance in the variables BMI and charges. This indicates that there is a mean difference in BMI and charges based on the region of the US a patient is from. The p value of the ANOVA tests for BMI and charges is &lt;2.2e-16 and 0.0308 respectively. When comparing the mean BMI and charges from each region, the southeast and southwest (33.3559, 30.5966) states have a higher BMI than the northeast and northwest (29.1735, 29.1997). The southeast part of the US have the highest mean charges on their health insurance of 14735.41 dollars while the southwest have the lowest mean charges of 12346.94 dollars.</p>
<p>Pairwise t tests were performed on both BMI and charges and compared to our corrected significance level of 0.00294. For BMI, there was a significant mean difference between the southeast to the northeast (p &lt; 2.2e-16), northwest (p &lt; 2.2e-16), and southwest (p = 8.5045e-10) and between the southwest to the northeast (p = 0.0019) and northwest (p = 0.0023) parts of the US. For charges, there was a significant mean difference between the southeast and southwest (p = 0.0097) parts of the US.</p>
<p>MANOVA assumptions include multivariate normality and variance-covariance homogeneity. When plotting a density plot to see multivariate normality, there are other parts of the graph that has high number of points (not concentrated). Therefore, this dataset fails the multivariate normality assumption. Next, looking at variance-covariance homogeneity, there are differences in variance and covariance from each region. Therefore, this datase would also fail the variance-covariance homogeneity assumption. Another assumption that MANOVA makes is that there is a linear relationship between the two dependent variables, which in this case is BMI and charges. Graphing the two variables does show that there is a linear trend and so this assumption is met. Of course, there are other assumptions that the MANOVA test makes, but these 3 assumptions were more interesting to look and analyze.</p>
</div>
<div id="randomization-test" class="section level3">
<h3>Randomization Test</h3>
<pre class="r"><code>insurance%&gt;%group_by(sex)%&gt;%
  summarize(means=mean(charges))%&gt;%summarize(`mean_diff`=diff(means))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   mean_diff
##       &lt;dbl&gt;
## 1    -1387.</code></pre>
<pre class="r"><code>rand_dist&lt;-vector() #create vector to hold diffs under null hypothesis

for(i in 1:5000){
new&lt;-data.frame(charges=sample(insurance$charges),sex=insurance$sex) #scramble columns
rand_dist[i]&lt;-mean(new[new$sex==&quot;1&quot;,]$charges)-   
              mean(new[new$sex==&quot;0&quot;,]$charges)} 
{hist(rand_dist,main=&quot;&quot;,ylab=&quot;&quot;); abline(v = c(-1387.17233389, 1387.17233389),col=&quot;red&quot;)}</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-3-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>mean(rand_dist&gt;1387.17233389 | rand_dist&lt; -1387.17233389)</code></pre>
<pre><code>## [1] 0.0388</code></pre>
<p>For my randomization test I decided to test if there was a mean difference in charges on a patients medical bill based on sex. My null hypothesis is that there is no mean difference between the medical bill charges of a female and male. My alternative hypothesis is that there is a mean difference between the medical bill charges of a female and male. I found that female patients have a mean charge of 1387.17 lower than male patients charges.</p>
<p>I then created a histogram showing the mean differences after randomization (null hypothesis plot) and also added on vertical lines to represent the mean difference (test statistic) between females and males. The resulting p value (p = 0.0352) after randomzation indicates that I can reject the null hypothesis to conclude that there is a significant mean difference between the medical charges of females and males.</p>
</div>
<div id="linear-regression-model" class="section level3">
<h3>Linear Regression Model</h3>
<pre class="r"><code>library(sandwich); library(lmtest)

# lm
insurance$bmi_c &lt;- insurance$bmi - mean(insurance$bmi)
insurance$charges_c &lt;- insurance$charges - mean(insurance$charges)
insurance$children_c &lt;- insurance$children - mean(insurance$children)
lm_fit &lt;- lm(charges_c~bmi_c*children_c, data = insurance)
summary(lm_fit)</code></pre>
<pre><code>## 
## Call:
## lm(formula = charges_c ~ bmi_c * children_c, data = insurance)
## 
## Residuals:
##    Min     1Q Median     3Q    Max 
## -19683  -8096  -3909   5003  50158 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)        -1.945    324.130  -0.006   0.9952    
## bmi_c             392.166     53.172   7.375 2.87e-13 ***
## children_c        659.285    268.997   2.451   0.0144 *  
## bmi_c:children_c   20.750     44.682   0.464   0.6424    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 11860 on 1334 degrees of freedom
## Multiple R-squared:  0.04378,    Adjusted R-squared:  0.04163 
## F-statistic: 20.36 on 3 and 1334 DF,  p-value: 6.672e-13</code></pre>
<pre class="r"><code># plotting fit
insurance %&gt;% ggplot(aes(bmi_c,charges,color=children))+geom_point()+geom_smooth(method=&quot;lm&quot;, se=F)</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-4-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code># assumptions
## linearity
lm_resids &lt;- lm_fit$residuals; lm_fitvals&lt;- lm_fit$fitted.values
ggplot()+geom_point(aes(lm_fitvals,lm_resids))+geom_hline(yintercept=0, col=&quot;red&quot;)</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-4-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## normality
ggplot()+geom_histogram(aes(lm_resids))</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-4-3.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## homoskedasticity 
bptest(lm_fit)</code></pre>
<pre><code>## 
##  studentized Breusch-Pagan test
## 
## data:  lm_fit
## BP = 118.81, df = 3, p-value &lt; 2.2e-16</code></pre>
<pre class="r"><code>coeftest(lm_fit, vcov = vcovHC(lm_fit))</code></pre>
<pre><code>## 
## t test of coefficients:
## 
##                  Estimate Std. Error t value  Pr(&gt;|t|)    
## (Intercept)       -1.9448   324.5470 -0.0060   0.99522    
## bmi_c            392.1665    57.8086  6.7839 1.754e-11 ***
## children_c       659.2848   258.6864  2.5486   0.01093 *  
## bmi_c:children_c  20.7503    46.0283  0.4508   0.65220    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>Looking at the coefficients from this linear regression before robust standard errors, when controlling for children, every 1 unit increase in centered BMI corresponds to a 362.28 dollar amount increase in charges on the patients medical bill. The coefficient for children states that for every increase in number of children the patient has while holding centered BMI constant, there will be a corresponding 659.28 dollar amount increase in health insurance charges. Finally, the interaction coefficient indicates that the slope for BMI on charges is 20.75 higher for every unit increase in children a patient has.</p>
<p>Looking at the assumptions of the linear regression model, the linearity assumption failed because there was not a linear trend when graphing the residuals against the fitted values. The normality of the regression failed since the histogram does not show a normal distribution of observations. Testing for homoskedasticity also failed sice the p-value was less than 0.05 so the standard errors were adjusted. After applying robust standard errors, the coefficients of the two independent variables and their interaction were pretty much the same as before. Both BMI and children without any interactions are significant on charges; however, there was no significant interaction between children and BMI on charges. The significance results were exactly the same prior to applying robust standardr errors.</p>
</div>
<div id="bootstrapped-linear-regression" class="section level2">
<h2>Bootstrapped Linear Regression</h2>
<pre class="r"><code>set.seed(348)
samp_distn &lt;- replicate(5000, {
  boot_dat &lt;- sample_frac(insurance, replace=T)
  fit &lt;- lm(charges_c ~ bmi_c*children_c, data = boot_dat)
  coef(fit)
})

samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% summarize_all(sd)</code></pre>
<pre><code>##   (Intercept)   bmi_c children_c bmi_c:children_c
## 1    324.0539 57.3682   261.4723         46.87936</code></pre>
<pre class="r"><code>samp_distn %&gt;% t %&gt;% as.data.frame %&gt;% gather %&gt;% group_by(key) %&gt;%
  summarize(lower=quantile(value,.025), upper=quantile(value,.975))</code></pre>
<pre><code>## # A tibble: 4 x 3
##   key               lower upper
##   &lt;chr&gt;             &lt;dbl&gt; &lt;dbl&gt;
## 1 (Intercept)      -607.   652.
## 2 bmi_c             283.   508.
## 3 bmi_c:children_c  -66.1  118.
## 4 children_c        162.  1190.</code></pre>
<p>After bootstrapping my standard errors by randomization, there was a slight change comparing my bootstrapped SEs to my original SEs. The bootstrapped SEs compared to the orignial SEs for BMI controlling for children and the interaction of BMI and number of children increased from 53.1717 to 57.3682 and 44.6820 to 46.8793 respectively. However, the original SE for children controlling for BMI decreased in the bootstrapped SEs from 268.9973 to 261.4722.</p>
<p>There was not much difference between the robust SEs and the bootstrapped SEs. The robust SE to the bootstrapped SE for BMI when controlling for BMI was 57.8085 and 56.9685 respectively. For children when controlling for BMI, the robust SE was 258.6864 and the bootstrapped SE was 257.5905. The interaction of BMI and children was mostly the same for both the robust SEs and the bootstrapped SEs.</p>
<p>Looking at the 95% confidence interval, 0 was not a value within the 95% CI for BMI when controlling for children and children when controlling for BMI, meaning that there is a significant difference on charge depending on the patient’s BMI or the number of children they have. On the other hand, 0 was a value within the range of the 95% CI for the interaction of BMI and children. This interaction is therefore not significant on charges.</p>
<div id="logistic-regression" class="section level3">
<h3>Logistic Regression</h3>
<pre class="r"><code>lr_fit &lt;- glm(smoker ~ bmi*charges, data = insurance, family = &quot;binomial&quot;)
summary(lr_fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = smoker ~ bmi * charges, family = &quot;binomial&quot;, data = insurance)
## 
## Deviance Residuals: 
##      Min        1Q    Median        3Q       Max  
## -3.01203  -0.17922  -0.07387  -0.01663   1.96220  
## 
## Coefficients:
##               Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)  1.595e+00  1.447e+00   1.103    0.270    
## bmi         -3.059e-01  5.676e-02  -5.391 7.03e-08 ***
## charges      2.904e-04  6.223e-05   4.667 3.06e-06 ***
## bmi:charges  9.749e-07  1.994e-06   0.489    0.625    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1356.63  on 1337  degrees of freedom
## Residual deviance:  392.49  on 1334  degrees of freedom
## AIC: 400.49
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<pre class="r"><code>exp(coef(lr_fit))</code></pre>
<pre><code>## (Intercept)         bmi     charges bmi:charges 
##   4.9291347   0.7364273   1.0002905   1.0000010</code></pre>
<pre class="r"><code># confusion matrix and AUC
prob &lt;- predict(lr_fit,type=&quot;response&quot;)
table(predict=as.numeric(prob&gt;.5),truth=insurance$smoker)%&gt;%addmargins</code></pre>
<pre><code>##        truth
## predict    0    1  Sum
##     0   1029   54 1083
##     1     35  220  255
##     Sum 1064  274 1338</code></pre>
<pre class="r"><code>220/274 #TPR</code></pre>
<pre><code>## [1] 0.8029197</code></pre>
<pre class="r"><code>1029/1064 #TNR</code></pre>
<pre><code>## [1] 0.9671053</code></pre>
<pre class="r"><code>220/255 #precision</code></pre>
<pre><code>## [1] 0.8627451</code></pre>
<pre class="r"><code>(1029+220)/1338 #accuracy</code></pre>
<pre><code>## [1] 0.9334828</code></pre>
<pre class="r"><code>class_diag &lt;- function(probs,truth){
  #CONFUSION MATRIX: CALCULATE ACCURACY, TPR, TNR, PPV
  tab&lt;-table(factor(probs&gt;.5,levels=c(&quot;FALSE&quot;,&quot;TRUE&quot;)),truth)
  acc=sum(diag(tab))/sum(tab)
  sens=tab[2,2]/colSums(tab)[2]
  spec=tab[1,1]/colSums(tab)[1]
  ppv=tab[2,2]/rowSums(tab)[2]
  f1=2*(sens*ppv)/(sens+ppv)

  if(is.numeric(truth)==FALSE &amp; is.logical(truth)==FALSE) truth&lt;-as.numeric(truth)-1
  
  #CALCULATE EXACT AUC
  ord&lt;-order(probs, decreasing=TRUE)
  probs &lt;- probs[ord]; truth &lt;- truth[ord]
  
  TPR=cumsum(truth)/max(1,sum(truth)) 
  FPR=cumsum(!truth)/max(1,sum(!truth))
  
  dup&lt;-c(probs[-1]&gt;=probs[-length(probs)], FALSE)
  TPR&lt;-c(0,TPR[!dup],1); FPR&lt;-c(0,FPR[!dup],1)
  n &lt;- length(TPR)
  auc&lt;- sum( ((TPR[-1]+TPR[-n])/2) * (FPR[-1]-FPR[-n]) )

  data.frame(acc,sens,spec,ppv,f1,auc)
}
class_diag(prob, insurance$smoker)</code></pre>
<pre><code>##         acc      sens      spec       ppv       f1       auc
## 1 0.9334828 0.8029197 0.9671053 0.8627451 0.831758 0.9823795</code></pre>
<pre class="r"><code># ggplot
insurance$logit &lt;- predict(lr_fit,type=&quot;link&quot;)
insurance %&gt;% ggplot() + geom_density (aes(logit,color=smoker,fill=smoker), alpha=.4)+
  theme(legend.position=c(.85,.85))+geom_vline(xintercept=0)+xlab(&quot;logit (log-odds)&quot;)+
  geom_rug(aes(logit,color=smoker))</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-6-1.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code># ROC
library(plotROC)
ROCplot&lt;-ggplot(insurance)+geom_roc(aes(d=smoker,m=prob), n.cuts=0) 
ROCplot</code></pre>
<p><img src="public/project/project2_files/figure-html/unnamed-chunk-6-2.png" width="672" style="display: block; margin: auto;" /></p>
<pre class="r"><code>calc_auc(ROCplot)</code></pre>
<pre><code>##   PANEL group       AUC
## 1     1    -1 0.9823761</code></pre>
<p>The coefficients on my logistical regression indicates the log odds of a patient being a smoker based on their BMI and charges on their health insurance. For every unit increase in BMI when holding charges constant, the odds of a patient being a smoker decrease by a factor of 0.7364. When holding BMI constant, every dollar increase in charges, the odds of a patient being a smoker increases by a factor of 1.0003. The interaction of BMI and charges increases the odds of the patient being a smoker by a factor of 1.000001.</p>
<p>The confusion matrix shows that the true positive rate is 0.8029 (220/274) and the true negative rate is 0.9671 (1029/1064); meaning that the probability of the detecting if the patient is a smoker if they actually are a smoker is 0.8029 and that the probability of detecting if the patient is a not a smoker if they actually don’t smoke. The precision value is 0.8627 (220/255) and accuracy is 0.9334 (1249/1338). Precision indicates that the proportion of patients that classified as smoking and actually smoke is 0.8627. Accuracy is the total number of correct predictions out of all outcomes and in this case.</p>
<p>The results for accuracy, sensitivity, specificity, and precision can also be obtained from the class_diag function, and they are exactly the same as the values I calculated by hand. The class_diag function also reports the AUC of the model and in this case it is 0.9823, meaning that this model is great at predicting our overall results.</p>
<p>The ROC curve plots my true positives against my false positive. The closer the ROC curve resembles a right angle, the more accurate the model is at predicting if a patient is a smoker. Since my curve looks similar to a right angle, it can be concluded that my model/fit is pretty accurate at distinguishing smokers from non smokers. Additionally, the AUC can also be calculated by summing up the total area under the ROC curve. The AUC is 0.9823 and exactly the same value as calculated from the class_diag function.</p>
</div>
<div id="logistical-regression-all" class="section level3">
<h3>Logistical Regression All</h3>
<pre class="r"><code># fit and class diagnostic
all_fit &lt;- glm(smoker ~ ., data = insurance, family = &quot;binomial&quot;)
summary(all_fit)</code></pre>
<pre><code>## 
## Call:
## glm(formula = smoker ~ ., family = &quot;binomial&quot;, data = insurance)
## 
## Deviance Residuals: 
##     Min       1Q   Median       3Q      Max  
## -3.3068  -0.1023  -0.0429  -0.0109   1.3208  
## 
## Coefficients: (3 not defined because of singularities)
##                   Estimate Std. Error z value Pr(&gt;|z|)    
## (Intercept)      8.0303220  2.3326931   3.443 0.000576 ***
## age             -0.1020316  0.0134321  -7.596 3.05e-14 ***
## sex             -0.5456382  0.3027481  -1.802 0.071501 .  
## bmi             -0.9315967  0.6001128  -1.552 0.120574    
## charges          0.0010247  0.0006776   1.512 0.130473    
## children        -0.2431650  0.1281294  -1.898 0.057721 .  
## regionnorthwest  0.1230902  0.4027940   0.306 0.759916    
## regionsoutheast  0.6332442  0.4204727   1.506 0.132060    
## regionsouthwest  0.3141490  0.4417367   0.711 0.476980    
## bmi_c                   NA         NA      NA       NA    
## charges_c               NA         NA      NA       NA    
## children_c              NA         NA      NA       NA    
## logit           -1.9871785  2.1257937  -0.935 0.349895    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 1356.63  on 1337  degrees of freedom
## Residual deviance:  301.74  on 1328  degrees of freedom
## AIC: 321.74
## 
## Number of Fisher Scoring iterations: 8</code></pre>
<pre class="r"><code>prob &lt;- predict(all_fit,type=&quot;response&quot;)
class_diag(prob, insurance$smoker)</code></pre>
<pre><code>##         acc      sens      spec   ppv        f1       auc
## 1 0.9656203 0.9708029 0.9642857 0.875 0.9204152 0.9862384</code></pre>
<pre class="r"><code># 10 fold
set.seed(348)
k=10

data &lt;- insurance[sample(nrow(insurance)),]
folds &lt;- cut(seq(1:nrow(insurance)),breaks=k,labels=F)

diags&lt;-NULL
for(i in 1:k){
  train&lt;-data[folds!=i,] 
  test&lt;-data[folds==i,]
  
  truth&lt;-test$smoker
  
  fit&lt;-glm(smoker ~ ., data=train, family=&quot;binomial&quot;)
  
  probs&lt;-predict(fit,newdata = test,type=&quot;response&quot;)
  
  diags&lt;-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean)</code></pre>
<pre><code>##         acc      sens      spec       ppv       f1       auc
## 1 0.9574122 0.9306382 0.9624498 0.8644101 0.893619 0.9854259</code></pre>
<pre class="r"><code># lasso
library(glmnet)
x&lt;-model.matrix(smoker ~ -1+., data=insurance) #the -1 drops the intercept
x&lt;-scale(x)
y&lt;-as.matrix(insurance$smoker)

cv&lt;-cv.glmnet(x,y, family=&quot;binomial&quot;)
lasso&lt;-glmnet(x,y,family=&quot;binomial&quot;,lambda=cv$lambda.1se)
coef(lasso)</code></pre>
<pre><code>## 14 x 1 sparse Matrix of class &quot;dgCMatrix&quot;
##                            s0
## (Intercept)     -3.183168e+00
## age             -8.538282e-01
## sex             -1.684762e-02
## bmi              .           
## charges          1.567739e-01
## children        -9.441474e-03
## regionnortheast  .           
## regionnorthwest  .           
## regionsoutheast  .           
## regionsouthwest  .           
## bmi_c            .           
## charges_c        5.613761e-07
## children_c      -3.482185e-05
## logit            3.425196e+00</code></pre>
<pre class="r"><code># 10 fold with lasso
k=10

data &lt;- insurance[sample(nrow(insurance)),]
folds &lt;- cut(seq(1:nrow(insurance)),breaks=k,labels=F)

diags&lt;-NULL
for(i in 1:k){
  train&lt;-data[folds!=i,] 
  test&lt;-data[folds==i,]
  
  truth&lt;-test$smoker
  
  fit&lt;-glm(smoker ~ . - region, data=train, family=&quot;binomial&quot;)
  
  probs&lt;-predict(fit,newdata = test,type=&quot;response&quot;)
  
  diags&lt;-rbind(diags,class_diag(probs,truth))
}
summarize_all(diags,mean)</code></pre>
<pre><code>##         acc      sens      spec       ppv        f1       auc
## 1 0.9588935 0.9414577 0.9634098 0.8697846 0.9030003 0.9849054</code></pre>
<p>Fitting all variables to predict for whether a patient smokes or not yielded an accuracy of 0.9656, sensitivity of 0.9708, specificity of 0.9642, precision of 0.875, and AUC of 0.9862 indicating that this model/fit is good at predicting smoker status from all variables. These class diagnostic results were actually quite similar to those in the previous logistic regression with only two variables.</p>
<p>Using the 10 fold CV, the mean of the accuracy, sensitivity, specificity, precision, and AUC is 0.9574, 0.9306, 0.9624, 0.8644, and 0.9854 respectively. Compared to the in sample class diagnostics, the out of sample diagnostics were all slightly lower, but not by much. This makes sense since I am training different parts of the data and modeling it, which will make it less accurate since it’s not completely based on the data. However, even with out sample modeling, the resulting model is great since the AUC is still really high.</p>
<p>Using lasso, I can identify the most important predictors of the smoker variable. Age, sex, BMI, charges, and children are significant in the end while region can be disregarded.</p>
<p>After removing region as a predictor from the regression model, the resulting accuracy, sensitivity, specificity, precision, and AUC are 0.9588, 0.9414, 0.9634, 0.8697, and 0.9849 respectively. Comparing this out of sample regression with the in sample original regression with all variables, accuracy, sensitivity, and precision decreased while specificity, precision, and AUC stayed around the same. On the other hand, when comparing the lassoed out of sample model to the full out of sample model there is not much difference between the class diagnostics. The largest change was in the sensitivity where the lassoed out of sample regression had a higher sensitivity. Overall, all three models were good fits of the data and are able to predict quite accurately whether a patient is a smoker.</p>
</div>
</div>
